## on KnowCluster
### mysql container
mkdir /mnt/knowtmp/mysql
docker run -d --restart=always --name p1_mysql -e MYSQL_ROOT_PASSWORD=KnowEnG -p 3306:3306 \
    -v /mnt/knowtmp/mysql:/var/lib/mysql mysql

### redis container
mkdir /mnt/knowtmp/redis
docker run -d --name p1_redis -p 6379:6379 -v /mnt/knowtmp/redis:/data \
   redis redis-server --appendonly yes --requirepass KnowEnG

### cloud9 container
docker run -d --privileged --restart=always --name project_c9 -h project1_c9 -p 8181:8181 \
    -v /var/run/docker.sock:/var/run/docker.sock \
    -v /usr/bin/docker:/bin/docker \
    -v /mnt/fast/knoweng:/workspace/fast \
    -v /mnt/shared:/workspace/shared \
    -v /mnt/knowtmp:/workspace/knowtmp \
    cblatti3/p1_cloud9:0.1 --auth project1:knowdev249

# neo4j containers
docker run -t --restart=always --name hdfs sequenceiq/hadoop-docker:latest /etc/bootstrap.sh -bash #ctrl+C to detach
docker run -d --restart=always --name mazerunner --link hdfs:hdfs kbastani/neo4j-graph-analytics:latest
docker run -t --restart=always --name p1_neo4j -p 7474:7474 \
    --link mazerunner:mazerunner --link hdfs:hdfs \
    -v /mnt/knowtmp/p1neo4j/data:/opt/data \
    kbastani/docker-neo4j #ctrl+C to detach

### update /etc/hosts
echo -e '192.17.176.156\tknowcluster01.dyndns.org\tknowcluster01' >> /etc/hosts


### copy pipeline code
cd /workspace/knowtmp/project1/
git clone https://github.com/KnowEnG/KnowNet_Pipeline.git
cd /workspace/fast/apps/
git clone https://github.com/KnowEnG/KnowNet_Pipeline.git
git checkout chronos_testing

### set environment vars
#### Test local mode
KNP_CHRONOS_URL='LOCAL'
KNP_LOCAL_DIR='/workspace/apps/KnowNet_Pipeline'
KNP_CLOUD_DIR='/workspace/apps/KnowNet_Pipeline'
KNP_SHARE_DIR='/workspace/tmp_shared/local_pipe'
KNP_DATA_PATH='data_local_pipe'
KNP_LOGS_PATH='logs_local_pipe'
KNP_MYSQL_HOST='172.17.0.3'
KNP_MYSQL_HOST='3306'
KNP_REDIS_HOST='172.17.0.4'
KNP_REDIS_PORT='6379'

### Test docker mode
mkdir -p /mnt/backup/
ln -s /workspace /mnt/backup/post3
KNP_CHRONOS_URL='DOCKER'
KNP_LOCAL_DIR='/workspace/apps/KnowNet_Pipeline'
KNP_CLOUD_DIR='/mnt/backup/post3/apps/KnowNet_Pipeline/'
KNP_SHARE_DIR='/mnt/backup/post3/apps/KnowNet_Pipeline/shared/'
KNP_DATA_PATH='data_docker_pipe'
KNP_LOGS_PATH='logs_docker_pipe'
KNP_MYSQL_HOST='knowcorey.dyndns.org'
KNP_MYSQL_PORT='3307'
KNP_REDIS_HOST='knowcorey.dyndns.org'
KNP_REDIS_PORT='6380'

#### Test chronos mode
ln -s /workspace/shared /mnt
ln -s /workspace/knowtmp /mnt
mkdir /mnt/fast/
ln -s /workspace/fast /mnt/fast/knoweng
KNP_CHRONOS_URL='knowcluster01.dyndns.org:4400'
KNP_LOCAL_DIR='/workspace/fast/apps/KnowNet_Pipeline'
KNP_CLOUD_DIR='/mnt/fast/knoweng/apps/KnowNet_Pipeline/'
KNP_SHARE_DIR='/mnt/shared/KnowNet_Pipeline/shared/'
KNP_DATA_PATH='data_chronos_pipe2'
KNP_LOGS_PATH='logs_chronos_pipe_45'
KNP_MYSQL_HOST='knowcluster01.dyndns.org'
KNP_MYSQL_PORT='3306'
KNP_REDIS_HOST='knowcluster01.dyndns.org'
KNP_REDIS_PORT='6379'


## setup pipeline
### reset everything
#### clear out mysql
KNP_CMD="mysql -h $KNP_MYSQL_HOST --port $KNP_MYSQL_PORT -uroot -pKnowEnG KnowNet \
    --execute \"drop database KnowNet;\""
echo $KNP_CMD

#### clear out redis
KNP_CMD="redis-cli -h $KNP_REDIS_HOST -p $KNP_REDIS_PORT -a KnowEnG FLUSHDB"
echo $KNP_CMD

#### clear files
for i in directory_setup_True ensembl ppi species id_map; do
    rm -r $KNP_LOGS_PATH/*$i*
    rm -r $KNP_DATA_PATH/*$i*
    rm -r $KNP_SHARE_DIR/$KNP_LOGS_PATH/*$i*
    rm -r $KNP_SHARE_DIR/$KNP_DATA_PATH/*$i*
done;

#### clear chronos queue
for c in 'knowcluster01.dyndns.org:4400' ; do
    curl -L -X GET $c/scheduler/jobs | sed 's#,#\n#g' | sed 's#\[##g' | grep name | grep -v command | sed 's#{"name":"##g' | sed 's#"##g' > /tmp/t.txt
    for s in 'map-' 'table-' 'check-' 'fetch-' 'setup' ; do
        echo $s
        for i in `grep "$s" /tmp/t.txt  `; do
            CMD="curl -L -X DELETE $c/scheduler/job/$i";
            echo "$CMD";
            eval "$CMD";
        done;
    done;
done;

### run setup pipeline
KNP_CMD="python3 code/workflow_utilities.py CHECK -su \
    -myh $KNP_MYSQL_HOST -myp $KNP_MYSQL_PORT \
    -ld $KNP_LOCAL_DIR -dp $KNP_DATA_PATH -lp $KNP_LOGS_PATH \
    -c $KNP_CHRONOS_URL -cd $KNP_CLOUD_DIR \
    -sd $KNP_SHARE_DIR"
echo $KNP_CMD

#    -rh $KNP_REDIS_HOST -rp $KNP_REDIS_PORT \

#### crude timing: 1 hr 18 min
./code/reports/enumerate_files.sh $KNP_SHARE_DIR/$KNP_DATA_PATH COUNTS $KNP_MYSQL_HOST \
    $KNP_REDIS_HOST $KNP_MYSQL_PORT $KNP_REDIS_PORT > tests/KN03build.$KNP_DATA_PATH.setup_44


## pipeline on two small sources
### reset everything
#### clear files
for i in biogrid blast dip go humannet intact kegg msigdb pathcom pfam reactome stringdb directory_setup_false; do
    rm -r $KNP_LOGS_PATH/*$i*
    rm -r $KNP_DATA_PATH/*$i*
    rm -r $KNP_SHARE_DIR/$KNP_LOGS_PATH/*$i*
    rm -r $KNP_SHARE_DIR/$KNP_DATA_PATH/*$i*
done;

#### clear chronos queue
for c in 'knowcluster01.dyndns.org:4400' ; do
    curl -L -X GET $c/scheduler/jobs | sed 's#,#\n#g' | sed 's#\[##g' | grep name | grep -v command | sed 's#{"name":"##g' | sed 's#"##g' > /tmp/t.txt
    for s in 'map-' 'table-' 'check-' 'fetch-' 'setup' ; do
        echo $s
        for i in `grep "$s" /tmp/t.txt  `; do
            CMD="curl -L -X DELETE $c/scheduler/job/$i";
            echo "$CMD";
            eval "$CMD";
        done;
    done;
done;

### run pipeline on 2 small sources kegg and dip
KNP_CMD="python3 code/workflow_utilities.py CHECK \
    -myh $KNP_MYSQL_HOST -myp $KNP_MYSQL_PORT \
    -ld $KNP_LOCAL_DIR -dp $KNP_DATA_PATH -lp $KNP_LOGS_PATH \
    -c $KNP_CHRONOS_URL -cd $KNP_CLOUD_DIR
    -sd $KNP_SHARE_DIR -p kegg,,dip"
echo $KNP_CMD

#    -rh $KNP_REDIS_HOST -rp $KNP_REDIS_PORT \

#### crude timing: seconds
./code/reports/enumerate_files.sh $KNP_SHARE_DIR/$KNP_DATA_PATH COUNTS $KNP_MYSQL_HOST \
    $KNP_REDIS_HOST $KNP_MYSQL_PORT $KNP_REDIS_PORT > tests/KN03build.$KNP_DATA_PATH.save_log4





